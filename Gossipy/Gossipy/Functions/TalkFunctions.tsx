console.log('Access File TalkFunctions.tsx ---------------------------------------------------------------------')


// ‚úÖ TalkFunctions.tsx
// Central orchestrator that connects:
// 1Ô∏è‚É£ AudioRecorderFunctions
// 2Ô∏è‚É£ SpeachToTextGenerationFunctions
// 3Ô∏è‚É£ TextToTextGenerationFunctions
// 4Ô∏è‚É£ TextToSpeachGenerationFunctions

import { recordAudio, stopRecording } from "./AudioRecorderFunctions";
import { convertSpeechFileToText } from "./SpeachToTextGenerationFunctions";
import { generateGeminiResponse } from "./TextToTextGenerationFunctions";
import { speakWithPolly } from "./TextToSpeachGenerationFunctions";

/**
 * Handles the entire voice conversation pipeline:
 * Speech ‚Üí Text ‚Üí Gemini ‚Üí Speech
 *
 * @param setIsProcessing - function to toggle loading UI
 * @param onTranscript - callback for showing recognized user speech text
 * @param onResponse - callback for showing Gemini response text
 */
export async function handleVoiceConversation(
  setIsProcessing: (val: boolean) => void,
  onTranscript: (text: string) => void,
  onResponse: (responseText: string) => void
) {
  try {
    console.log("üéôÔ∏è Starting voice conversation...");
    setIsProcessing(true);

    // ------------------------------------------------------
    // 1Ô∏è‚É£ RECORD AUDIO
    // ------------------------------------------------------
    const audioUri = await recordAudio();
    console.log("‚úÖ Audio recorded at:", audioUri);

    // ------------------------------------------------------
    // 2Ô∏è‚É£ SPEECH ‚ûú TEXT
    // ------------------------------------------------------
    const transcript = await convertSpeechFileToText(audioUri, "en-IN"); // you can use "hi-IN" for Hindi
    console.log("üó£Ô∏è Transcript:", transcript);

    if (!transcript || transcript.trim().length === 0) {
      throw new Error("Speech-to-text conversion failed or empty transcript.");
    }

    // Show recognized user text in UI
    onTranscript(transcript);

    // ------------------------------------------------------
    // 3Ô∏è‚É£ TEXT ‚ûú GEMINI (TEXT RESPONSE)
    // ------------------------------------------------------
    const aiResponse = await generateGeminiResponse(transcript);
    console.log("ü§ñ Gemini response:", aiResponse);

    if (!aiResponse || aiResponse.trim().length === 0) {
      throw new Error("Gemini did not return any response.");
    }

    // Show AI response text in UI
    onResponse(aiResponse);

    // ------------------------------------------------------
    // 4Ô∏è‚É£ TEXT ‚ûú SPEECH (PLAY RESPONSE)
    // ------------------------------------------------------
    await speakWithPolly(aiResponse);
    console.log("üîä Polly spoke the response successfully!");
  } catch (error: any) {
    console.error("‚ùå handleVoiceConversation error:", error.message || error);
  } finally {
    setIsProcessing(false);
    console.log("‚úÖ Conversation flow ended.");
  }
}

/**
 * Optional helper: allows only Text‚ÜíText‚ÜíSpeech conversion
 * (for when user types a message instead of recording)
 */
export async function handleTypedConversation(
  inputText: string,
  setIsProcessing: (val: boolean) => void,
  onResponse: (responseText: string) => void
) {
  try {
    setIsProcessing(true);

    // 1Ô∏è‚É£ Generate Gemini text
    const aiResponse = await generateGeminiResponse(inputText);
    onResponse(aiResponse);

    // 2Ô∏è‚É£ Speak response
    await speakWithPolly(aiResponse);
  } catch (error: any) {
    console.error("‚ùå handleTypedConversation error:", error.message || error);
  } finally {
    setIsProcessing(false);
  }
}
